{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Read in word list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import src.utils.git as gitutil\n",
    "bpath = gitutil.get_root()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "word_list_name = 'twl06.txt'\n",
    "\n",
    "word_list_file = bpath + '/data/processed/' + word_list_name\n",
    "\n",
    "with open(word_list_file, 'r') as f:\n",
    "    word_list = f.read().splitlines()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Initialise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "possible_words = word_list"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Read in pre-calculated full cross-check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "full_cross_check = np.load(bpath + '/data/processed/full_cross_check.npy')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Retrieve diagonals to get letters in correct positions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "diags = np.diagonal(full_cross_check, axis1=2, axis2=3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Determine remaining letters in incorrect positions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Take row maxes excluding diagonals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "rowmaxes = np.logical_and((np.tril(full_cross_check, -1) + np.triu(full_cross_check, 1)).max(axis=3), ~diags)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Concatenate diag and rowmax outputs to find unique combinations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "diag_rowmax = np.concatenate((diags, rowmaxes), axis=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Encode 10 element boolean vector as binary number"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "diag_rowmax_bin_encode = np.matmul(diag_rowmax, np.array([2**i for i in range(9, -1, -1)]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Count frequencies of outcomes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "from math import log\n",
    "\n",
    "def calc_entropy(diag_rowmax_bin_encode, element, log_base):\n",
    "\n",
    "    # Determine number of possible remaining words\n",
    "    num_poss_remaining = len(diag_rowmax_bin_encode[element])\n",
    "\n",
    "    # Count frequency of each binary encoded outcome\n",
    "    counts = Counter(diag_rowmax_bin_encode[element])\n",
    "\n",
    "    # Calculate expected entropy\n",
    "    entropy = sum([(tup[1]/num_poss_remaining) * log(1/tup[1],log_base) for tup in list(counts.items())])\n",
    "\n",
    "    return(entropy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "entropies = [calc_entropy(diag_rowmax_bin_encode, i, 2) for i in range(len(diag_rowmax_bin_encode))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-6.911970966408277"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max(entropies)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'tares'"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "possible_words[entropies.index(max(entropies))]"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "7cf9aac655d88b65655cb66959072bdec5e8b779b329c22e6732fd20c845dfae"
  },
  "kernelspec": {
   "display_name": "Python 3.7.3 64-bit ('.venv_wordle_solver': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
